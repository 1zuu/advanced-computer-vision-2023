{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtDhCfXAGXncKr5dgU94sB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1zuu/advanced-computer-vision-2023/blob/main/object%20detection/1_yolov4_tiny_object_detection_training_public_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we implement the tiny version of [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf) for training on your own dataset, [YOLOv4 tiny](https://github.com/AlexeyAB/darknet/issues/6067).\n",
        "\n",
        "Following contains the steps to implement YOLOv4 on our custom data:\n",
        "1. Configure our GPU environment on Google Colab\n",
        "2. Install the Darknet YOLOv4 in Colab environment\n",
        "3. Download our custom dataset for YOLOv4 and set up directories\n",
        "4. Configure a custom YOLOv4 training config file for Darknet\n",
        "5. Train our custom YOLOv4 object detector\n",
        "6. YOLOv4 Custom Inference"
      ],
      "metadata": {
        "id": "lumgDCXk4fze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One thing to not is that YoloV4 is a **Huge Upgrade From YOLOv3**\n",
        "\n"
      ],
      "metadata": {
        "id": "RxvKF0i858rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Installing Dependencies"
      ],
      "metadata": {
        "id": "mU9ysT_T-qx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "id": "TxMx7p5w-tlZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Configure CUDA/cuDNN (GPU) on Google Colab"
      ],
      "metadata": {
        "id": "JynTj2vh5q5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Check cuDNN version\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "metadata": {
        "id": "SyXFrDsM4gOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d45186-c417-4d37-aa59-7a99e42a195c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsxP5wUi7oJ3",
        "outputId": "2ceb29bd-17a2-4066-dad7-ee5ab68a5313"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  2 14:55:05 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "            \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "            \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "            \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "            \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "            \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "            \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "          }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqv8F5aI7zlf",
        "outputId": "61e6bd7e-622e-46f3-c459-5537c0cb35f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Type: Tesla T4\n",
            "\n",
            "ARCH Value: -gencode arch=compute_75,code=[sm_75,compute_75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn_DW8_a5j5I",
        "outputId": "b3cb11ab-40e0-4689-818f-da8477486500"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdpqeAmi6Cap",
        "outputId": "3181b47f-e6d7-439f-937c-2c27cc26ef9b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir = '/content/drive/MyDrive/Colab Notebooks'\n",
        "os.chdir(working_dir)"
      ],
      "metadata": {
        "id": "JeEHtYdV6AAL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Install the Darknet YOLOv4 in Colab environment"
      ],
      "metadata": {
        "id": "k3rH6HEC8IbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/'Colab Notebooks'/darknet"
      ],
      "metadata": {
        "id": "pyfWyMRQ83iP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/roboflow-ai/darknet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h0AUzuf767e",
        "outputId": "711ed272-8bf6-4993-ab77-47a62ebf5221"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 13289, done.\u001b[K\n",
            "remote: Total 13289 (delta 0), reused 0 (delta 0), pack-reused 13289\u001b[K\n",
            "Receiving objects: 100% (13289/13289), 12.17 MiB | 11.68 MiB/s, done.\n",
            "Resolving deltas: 100% (9047/9047), done.\n",
            "Updating files: 100% (2002/2002), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install environment from the Makefile\n",
        "%cd /content/drive/MyDrive/'Colab Notebooks'/darknet/\n",
        "# compute_37, sm_37 for Tesla K80\n",
        "# compute_75, sm_75 for Tesla T4\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_75,code=sm_75/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmoI_qK38Rb3",
        "outputId": "674cde24-a21e-4982-9d0a-3f52c26ee0fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/darknet\n",
            "mkdir -p ./obj/\n",
            "mkdir -p backup\n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_detections_cv_v3(void**, detection*, int, float, char**, image**, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:910:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Krgb\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "  910 |                 float \u001b[01;35m\u001b[Krgb\u001b[m\u001b[K[3];\n",
            "      |                       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cv_draw_object(image, float*, int, int, int*, float*, int*, int, char**)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1391:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuff\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 1391 |         char \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K[100];\n",
            "      |              \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1367:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kit_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 1367 |     int \u001b[01;35m\u001b[Kit_tb_res\u001b[m\u001b[K = cv::createTrackbar(it_trackbar_name, window_name, &it_trackbar_value, 1000);\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1371:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klr_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 1371 |     int \u001b[01;35m\u001b[Klr_tb_res\u001b[m\u001b[K = cv::createTrackbar(lr_trackbar_name, window_name, &lr_trackbar_value, 20);\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1375:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcl_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 1375 |     int \u001b[01;35m\u001b[Kcl_tb_res\u001b[m\u001b[K = cv::createTrackbar(cl_trackbar_name, window_name, &cl_trackbar_value, classes-1);\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1378:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbo_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 1378 |     int \u001b[01;35m\u001b[Kbo_tb_res\u001b[m\u001b[K = cv::createTrackbar(bo_trackbar_name, window_name, boxonly, 1);\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/http_stream.cpp -o obj/http_stream.o\n",
            "In file included from \u001b[01m\u001b[K./src/http_stream.cpp:580\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K./src/httplib.h:129:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K\"INVALID_SOCKET\" redefined\n",
            "  129 | #define INVALID_SOCKET (-1)\n",
            "      | \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:73:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kthis is the location of the previous definition\n",
            "   73 | #define INVALID_SOCKET -1\n",
            "      | \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:249:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "  249 |                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
            "      |                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool MJPG_sender::write(const cv::Mat&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:507:95:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%zu\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  507 |                 sprintf(head, \"--mjpegstream\\r\\nContent-Type: image/jpeg\\r\\nContent-Length: \u001b[01;35m\u001b[K%zu\u001b[m\u001b[K\\r\\n\\r\\n\", \u001b[32m\u001b[Koutlen\u001b[m\u001b[K);\n",
            "      |                                                                                             \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K           \u001b[32m\u001b[K~~~~~~\u001b[m\u001b[K\n",
            "      |                                                                                               \u001b[01;35m\u001b[K|\u001b[m\u001b[K           \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                                               \u001b[01;35m\u001b[K|\u001b[m\u001b[K           \u001b[32m\u001b[Kint\u001b[m\u001b[K\n",
            "      |                                                                                               \u001b[01;35m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "      |                                                                                             \u001b[32m\u001b[K%u\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/gemm.c -o obj/gemm.o\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:2039:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 2039 |     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
            "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gemm.c:2038:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            " 2038 |     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
            "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/utils.c -o obj/utils.o\n",
            "In file included from \u001b[01m\u001b[K/usr/include/string.h:495\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/utils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/utils.c:4\u001b[m\u001b[K:\n",
            "In function ‘\u001b[01m\u001b[Kstrncpy\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[Kcopy_string\u001b[m\u001b[K’ at \u001b[01m\u001b[K./src/utils.c:509:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:106:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin_strncpy\u001b[m\u001b[K’ specified bound depends on the length of the source argument [\u001b[01;35m\u001b[K-Wstringop-overflow=\u001b[m\u001b[K]\n",
            "  106 |   return \u001b[01;35m\u001b[K__builtin___strncpy_chk (__dest, __src, __len, __bos (__dest))\u001b[m\u001b[K;\n",
            "      |          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/utils.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcopy_string\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/utils.c:509:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Klength computed here\n",
            "  509 |     strncpy(copy, s, \u001b[01;36m\u001b[Kstrlen(s)\u001b[m\u001b[K+1);\n",
            "      |                      \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_check_error_extended\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:224:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcudaError_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kenum <anonymous>\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "  224 |         if (status \u001b[01;35m\u001b[K!=\u001b[m\u001b[K CUDNN_STATUS_SUCCESS)\n",
            "      |                    \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpre_allocate_pinned_memory\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  276 |         printf(\"pre_allocate: size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB, num_of_blocks = %Iu, block_size = %Iu MB \\n\",\n",
            "      |                                      \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "      |                                        \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                        \u001b[01;35m\u001b[Kunsigned int\u001b[m\u001b[K\n",
            "      |                                      \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "  277 |             \u001b[32m\u001b[Ksize / (1024*1024)\u001b[m\u001b[K, num_of_blocks, pinned_block_size / (1024 * 1024));\n",
            "      |             \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K          \n",
            "      |                  \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                  \u001b[32m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kconst long unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  276 |         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K, block_size = %Iu MB \\n\",\n",
            "      |                                                              \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "      |                                                                \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                \u001b[01;35m\u001b[Kunsigned int\u001b[m\u001b[K\n",
            "      |                                                              \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "  277 |             size / (1024*1024), \u001b[32m\u001b[Knum_of_blocks\u001b[m\u001b[K, pinned_block_size / (1024 * 1024));\n",
            "      |                                 \u001b[32m\u001b[K~~~~~~~~~~~~~\u001b[m\u001b[K                   \n",
            "      |                                 \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                 \u001b[32m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:82:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  276 |         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = %Iu, block_size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB \\n\",\n",
            "      |                                                                                \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "      |                                                                                  \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                                  \u001b[01;35m\u001b[Kunsigned int\u001b[m\u001b[K\n",
            "      |                                                                                \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "  277 |             size / (1024*1024), num_of_blocks, \u001b[32m\u001b[Kpinned_block_size / (1024 * 1024)\u001b[m\u001b[K);\n",
            "      |                                                \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K  \n",
            "      |                                                                  \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                  \u001b[32m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:286:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  286 |                 printf(\" Allocated \u001b[01;35m\u001b[K%d\u001b[m\u001b[K pinned block \\n\", \u001b[32m\u001b[Kpinned_block_size\u001b[m\u001b[K);\n",
            "      |                                    \u001b[01;35m\u001b[K~^\u001b[m\u001b[K                   \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                                     \u001b[01;35m\u001b[K|\u001b[m\u001b[K                   \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                     \u001b[01;35m\u001b[Kint\u001b[m\u001b[K                 \u001b[32m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "      |                                    \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcuda_make_array_pinned_preallocated\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:307:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  307 |             printf(\"\\n Pinned block_id = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, filled = %f %% \\n\", \u001b[32m\u001b[Kpinned_block_id\u001b[m\u001b[K, filled);\n",
            "      |                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K                      \u001b[32m\u001b[K~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                                           \u001b[01;35m\u001b[K|\u001b[m\u001b[K                      \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                           \u001b[01;35m\u001b[Kint\u001b[m\u001b[K                    \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
            "      |                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:322:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  322 |             printf(\"Try to allocate new pinned memory, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "      |                                                               \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                                                                \u001b[01;35m\u001b[K|\u001b[m\u001b[K              \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                                \u001b[01;35m\u001b[Kint\u001b[m\u001b[K            \u001b[32m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "      |                                                               \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:328:63:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "  328 |             printf(\"Try to allocate new pinned BLOCK, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "      |                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                                                               \u001b[01;35m\u001b[K|\u001b[m\u001b[K              \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                               \u001b[01;35m\u001b[Kint\u001b[m\u001b[K            \u001b[32m\u001b[Klong unsigned int\u001b[m\u001b[K\n",
            "      |                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_convolutional_setup\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:286:24:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[KCUDNN_CONVOLUTION_FWD_PREFER_FASTEST\u001b[m\u001b[K’ undeclared (first use in this function); did you mean ‘\u001b[01m\u001b[KCUDNN_CONVOLUTION_BWD_FILTER_ALGO_3\u001b[m\u001b[K’?\n",
            "  286 |     int forward_algo = \u001b[01;31m\u001b[KCUDNN_CONVOLUTION_FWD_PREFER_FASTEST\u001b[m\u001b[K;\n",
            "      |                        \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                        \u001b[32m\u001b[KCUDNN_CONVOLUTION_BWD_FILTER_ALGO_3\u001b[m\u001b[K\n",
            "compilation terminated due to -Wfatal-errors.\n",
            "make: *** [Makefile:162: obj/convolutional_layer.o] Error 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G58ge-EM80ka",
        "outputId": "2fe9f766-a591-4df6-f32d-df828f20d077"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m3rdparty\u001b[0m/     \u001b[01;34mcmake\u001b[0m/                  \u001b[01;32mimage_yolov3.sh\u001b[0m*        README.md\n",
            "appveyor.yml  CMakeLists.txt          \u001b[01;34minclude\u001b[0m/                \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mbackup\u001b[0m/       DarknetConfig.cmake.in  \u001b[01;32mjson_mjpeg_streams.sh\u001b[0m*  \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34mbuild\u001b[0m/        darknet.py              LICENSE                 \u001b[01;34msrc\u001b[0m/\n",
            "build.ps1     darknet_video.py        Makefile                \u001b[01;32mvideo_v2.sh\u001b[0m*\n",
            "\u001b[01;32mbuild.sh\u001b[0m*     \u001b[01;34mdata\u001b[0m/                   \u001b[01;32mnet_cam_v3.sh\u001b[0m*          \u001b[01;32mvideo_yolov3.sh\u001b[0m*\n",
            "\u001b[01;34mcfg\u001b[0m/          \u001b[01;32mimage_yolov2.sh\u001b[0m*        \u001b[01;34mobj\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SVGICZns832U",
        "outputId": "7dac898a-a889-4059-c92a-d4ba292fa733"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/darknet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaBfQFx28k-v",
        "outputId": "5d1b50f2-c265-458b-a05a-26a8dcbfc63e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-02 14:59:17--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/228a9c00-3ea4-11eb-8e80-28d71569f56c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230502T145724Z&X-Amz-Expires=300&X-Amz-Signature=e16f85ebafcc1f45ff554654eb6020d64413e8a978f184c3a5df6f69e8a68ea5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-02 14:59:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/228a9c00-3ea4-11eb-8e80-28d71569f56c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230502T145724Z&X-Amz-Expires=300&X-Amz-Signature=e16f85ebafcc1f45ff554654eb6020d64413e8a978f184c3a5df6f69e8a68ea5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24251276 (23M) [application/octet-stream]\n",
            "Saving to: ‘yolov4-tiny.weights’\n",
            "\n",
            "yolov4-tiny.weights 100%[===================>]  23.13M  70.1MB/s    in 0.3s    \n",
            "\n",
            "2023-05-02 14:59:17 (70.1 MB/s) - ‘yolov4-tiny.weights’ saved [24251276/24251276]\n",
            "\n",
            "--2023-05-02 14:59:18--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/28807d00-3ea4-11eb-97b5-4c846ecd1d05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230502T145918Z&X-Amz-Expires=300&X-Amz-Signature=ff0c2d6d289e3f8b6ea0e423593c57d987866955093d7f54888a1ad9a8f43356&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.conv.29&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-02 14:59:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/28807d00-3ea4-11eb-97b5-4c846ecd1d05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230502T145918Z&X-Amz-Expires=300&X-Amz-Signature=ff0c2d6d289e3f8b6ea0e423593c57d987866955093d7f54888a1ad9a8f43356&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4-tiny.conv.29&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19789716 (19M) [application/octet-stream]\n",
            "Saving to: ‘yolov4-tiny.conv.29’\n",
            "\n",
            "yolov4-tiny.conv.29 100%[===================>]  18.87M  54.8MB/s    in 0.3s    \n",
            "\n",
            "2023-05-02 14:59:18 (54.8 MB/s) - ‘yolov4-tiny.conv.29’ saved [19789716/19789716]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Download our custom dataset for YOLOv4 and set up directories"
      ],
      "metadata": {
        "id": "HvWZCvyh_5-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roboflow is Amazing tool to handle cumbersome computer vision data pipelines in much more easier way on both public and custom datasets. SO I use Roboflow to convert our dataset from any format to the YOLO Darknet format. \n",
        "\n",
        "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
        "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
        "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
        "4. Export your dataset in the **YOLO Darknet format**.\n",
        "5. Copy your download link, and paste it below.\n",
        "\n",
        "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
      ],
      "metadata": {
        "id": "pA9FM5BP-1Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "id": "P7WH-Q_wABuU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"ZZ7HJ3HnL7AQsaOsm25o\")\n",
        "project = rf.workspace(\"edrogen\").project(\"bccd-avvoy\")\n",
        "dataset = project.version(1).download(\"darknet\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W21GjrQI86G1",
        "outputId": "b19d704e-27f3-4c85-c939-2872c8603055"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in BCCD-1 to darknet: 100% [13305888 / 13305888] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to BCCD-1 in darknet:: 100%|██████████| 1755/1755 [00:11<00:00, 148.04it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<roboflow.core.dataset.Dataset at 0x7f9187a076d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rS836SmE7y9B",
        "outputId": "c059bae5-1040-4c3e-d8f4-7df544d0a6ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/darknet/BCCD-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sgZGd20_LsS",
        "outputId": "65b1fc54-41db-4c90-89b4-a0ab6e60284a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m3rdparty\u001b[0m/       DarknetConfig.cmake.in  \u001b[01;32mnet_cam_v3.sh\u001b[0m*\n",
            "appveyor.yml    darknet.py              \u001b[01;34mobj\u001b[0m/\n",
            "\u001b[01;34mbackup\u001b[0m/         darknet_video.py        README.md\n",
            "\u001b[01;34mBCCD-1\u001b[0m/         \u001b[01;34mdata\u001b[0m/                   \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mbuild\u001b[0m/          \u001b[01;32mimage_yolov2.sh\u001b[0m*        \u001b[01;34mscripts\u001b[0m/\n",
            "build.ps1       \u001b[01;32mimage_yolov3.sh\u001b[0m*        \u001b[01;34msrc\u001b[0m/\n",
            "\u001b[01;32mbuild.sh\u001b[0m*       \u001b[01;34minclude\u001b[0m/                \u001b[01;32mvideo_v2.sh\u001b[0m*\n",
            "\u001b[01;34mcfg\u001b[0m/            \u001b[01;32mjson_mjpeg_streams.sh\u001b[0m*  \u001b[01;32mvideo_yolov3.sh\u001b[0m*\n",
            "\u001b[01;34mcmake\u001b[0m/          LICENSE                 yolov4-tiny.conv.29\n",
            "CMakeLists.txt  Makefile                yolov4-tiny.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd {working_dir}/darknet/\n",
        "%cp {dataset.location}/train/_darknet.labels {working_dir}/darknet/data/obj.names\n",
        "%mkdir {working_dir}/darknet/data/obj\n",
        "\n",
        "#copy image and labels\n",
        "%cp {dataset.location}/train/*.jpg {working_dir}/darknet/data/obj/\n",
        "%cp {dataset.location}/valid/*.jpg {working_dir}/darknet/data/obj/\n",
        "\n",
        "%cp {dataset.location}/train/*.txt {working_dir}/darknet/data/obj/\n",
        "%cp {dataset.location}/valid/*.txt {working_dir}/darknet/data/obj/\n",
        "\n",
        "with open(f'{working_dir}/darknet/data/obj.data', 'w') as out:\n",
        "      out.write('classes = 3\\n')\n",
        "      out.write('train = data/train.txt\\n')\n",
        "      out.write('valid = data/valid.txt\\n')\n",
        "      out.write('names = data/obj.names\\n')\n",
        "      out.write('backup = backup/')\n",
        "\n",
        "#write train file (just the image list)\n",
        "import os\n",
        "\n",
        "with open(f'{working_dir}/darknet/data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/train') if f.endswith('jpg')]:\n",
        "    out.write(f'{working_dir}/darknet/data/obj/' + img + '\\n')\n",
        "\n",
        "#write the valid file (just the image list)\n",
        "import os\n",
        "\n",
        "with open(f'{working_dir}/darknet/data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir(dataset.location + '/valid') if f.endswith('jpg')]:\n",
        "    out.write(f'{working_dir}/darknet/data/obj/' + img + '\\n')"
      ],
      "metadata": {
        "id": "DwzM836fBUI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ed180d-a97d-4ebf-daf3-33c375d7eb1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/darknet\n",
            "cp: target '/content/drive/MyDrive/Colab Notebooks/darknet/data/obj.names' is not a directory\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Colab Notebooks/darknet/data/obj’: File exists\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n",
            "cp: cannot stat 'Notebooks/darknet/BCCD-1/train/*.jpg': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n",
            "cp: cannot stat 'Notebooks/darknet/BCCD-1/valid/*.jpg': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n",
            "cp: cannot stat 'Notebooks/darknet/BCCD-1/train/*.txt': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab': No such file or directory\n",
            "cp: cannot stat 'Notebooks/darknet/BCCD-1/valid/*.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Configure a custom YOLOv4 training config file for Darknet"
      ],
      "metadata": {
        "id": "UaSw23bk2EeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we build config dynamically based on number of classes\n",
        "#we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len(dataset.location + '/train/_darknet.labels')\n",
        "max_batches = num_classes*2000 # 2000 iterations per class\n",
        "steps1 = .8 * max_batches\n",
        "steps2 = .9 * max_batches\n",
        "steps_str = str(steps1)+','+str(steps2)\n",
        "num_filters = (num_classes + 5) * 3\n",
        "\n",
        "\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of training images, and not less than 6000), f.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, f.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-tiny-detector.cfg'): os.remove('./cfg/custom-yolov4-tiny-detector.cfg')\n",
        "\n",
        "\n",
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAaT7o6o14kM",
        "outputId": "8383e051-6a1c-4dda-fe8e-a0b0f8a661d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing config for a custom YOLOv4 detector detecting number of classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writetemplate ./cfg/custom-yolov4-tiny-detector.cfg\n",
        "[net]\n",
        "# Testing\n",
        "#batch=1\n",
        "#subdivisions=1\n",
        "# Training\n",
        "batch=64\n",
        "subdivisions=24\n",
        "width=416\n",
        "height=416\n",
        "channels=3\n",
        "momentum=0.9\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = {max_batches}\n",
        "policy=steps\n",
        "steps={steps_str}\n",
        "scales=.1,.1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=32\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers=-1\n",
        "groups=2\n",
        "group_id=1\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -1,-2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[route]\n",
        "layers = -6,-1\n",
        "\n",
        "[maxpool]\n",
        "size=2\n",
        "stride=2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "##################################\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "[route]\n",
        "layers = -4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = -1, 23\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=leaky\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[yolo]\n",
        "mask = 1,2,3\n",
        "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
        "classes={num_classes}\n",
        "num=6\n",
        "jitter=.3\n",
        "scale_x_y = 1.05\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=0\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6"
      ],
      "metadata": {
        "id": "5pSEPNh_2uFT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cat cfg/custom-yolov4-tiny-detector.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Aqg0It-3H8T",
        "outputId": "bac109c0-37f2-47b4-d1ce-a499d801f14f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[net]\n",
            "# Testing\n",
            "#batch=1\n",
            "#subdivisions=1\n",
            "# Training\n",
            "batch=64\n",
            "subdivisions=24\n",
            "width=416\n",
            "height=416\n",
            "channels=3\n",
            "momentum=0.9\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "learning_rate=0.00261\n",
            "burn_in=1000\n",
            "max_batches = 6000\n",
            "policy=steps\n",
            "steps=4800.0,5400.0\n",
            "scales=.1,.1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1\n",
            "groups=2\n",
            "group_id=1\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -1,-2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers = -6,-1\n",
            "\n",
            "[maxpool]\n",
            "size=2\n",
            "stride=2\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "##################################\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=24\n",
            "activation=linear\n",
            "\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
            "classes=3\n",
            "num=6\n",
            "jitter=.3\n",
            "scale_x_y = 1.05\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n",
            "\n",
            "[route]\n",
            "layers = -4\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 23\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=24\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 1,2,3\n",
            "anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319\n",
            "classes=3\n",
            "num=6\n",
            "jitter=.3\n",
            "scale_x_y = 1.05\n",
            "cls_normalizer=1.0\n",
            "iou_normalizer=0.07\n",
            "iou_loss=ciou\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "nms_kind=greedynms\n",
            "beta_nms=0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Train our custom YOLOv4 object detector"
      ],
      "metadata": {
        "id": "dg4Vy9qQ3VxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk5jGltY3OvE",
        "outputId": "99574274-fb2c-470d-8182-ca6ec7731999"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./darknet: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FvrMIc23bEt",
        "outputId": "11fb1348-ffe8-4823-cab8-001786b0d955"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m3rdparty\u001b[0m/       DarknetConfig.cmake.in  \u001b[01;32mnet_cam_v3.sh\u001b[0m*\n",
            "appveyor.yml    darknet.py              \u001b[01;34mobj\u001b[0m/\n",
            "\u001b[01;34mbackup\u001b[0m/         darknet_video.py        README.md\n",
            "\u001b[01;34mBCCD-1\u001b[0m/         \u001b[01;34mdata\u001b[0m/                   \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mbuild\u001b[0m/          \u001b[01;32mimage_yolov2.sh\u001b[0m*        \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;32mbuild.ps1\u001b[0m*      \u001b[01;32mimage_yolov3.sh\u001b[0m*        \u001b[01;34msrc\u001b[0m/\n",
            "\u001b[01;32mbuild.sh\u001b[0m*       \u001b[01;34minclude\u001b[0m/                \u001b[01;32mvideo_v2.sh\u001b[0m*\n",
            "\u001b[01;34mcfg\u001b[0m/            \u001b[01;32mjson_mjpeg_streams.sh\u001b[0m*  \u001b[01;32mvideo_yolov3.sh\u001b[0m*\n",
            "\u001b[01;34mcmake\u001b[0m/          LICENSE                 yolov4-tiny.conv.29\n",
            "CMakeLists.txt  Makefile                yolov4-tiny.weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-puLuZjg3eec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}